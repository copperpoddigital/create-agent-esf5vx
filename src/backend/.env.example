# Environment: development, staging, production
APP_ENV=development
# Application name
APP_NAME=Document Management and AI Chatbot
# API prefix for all endpoints
APP_API_V1_PREFIX=/api/v1
# Debug mode (True/False)
APP_DEBUG=True
# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
APP_LOG_LEVEL=INFO
# Allowed CORS origins (comma-separated list)
APP_CORS_ALLOW_ORIGINS=http://localhost:3000,http://localhost:8080
# API rate limit per minute
APP_RATE_LIMIT_PER_MINUTE=60

# Database Settings
# PostgreSQL connection string (takes precedence if provided)
DB_SQLALCHEMY_DATABASE_URI=postgresql://postgres:postgres@localhost:5432/document_management
# Alternative individual database connection parameters
# Used if SQLALCHEMY_DATABASE_URI is not provided
DB_POSTGRES_USER=postgres
DB_POSTGRES_PASSWORD=postgres
DB_POSTGRES_HOST=localhost
DB_POSTGRES_PORT=5432
DB_POSTGRES_DB=document_management
# Connection pool settings
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10
DB_POOL_TIMEOUT=30
# Whether to log SQL queries (True/False)
DB_ECHO_SQL=False

# Security Settings
# JWT secret key (CHANGE THIS IN PRODUCTION!)
SECURITY_JWT_SECRET=your-secret-key-change-in-production
# JWT algorithm
SECURITY_JWT_ALGORITHM=HS256
# JWT access token expiration time in minutes
SECURITY_ACCESS_TOKEN_EXPIRE_MINUTES=60
# JWT refresh token expiration time in days
SECURITY_REFRESH_TOKEN_EXPIRE_DAYS=7
# Password policy settings
SECURITY_PASSWORD_MIN_LENGTH=10
SECURITY_PASSWORD_REQUIRE_UPPERCASE=True
SECURITY_PASSWORD_REQUIRE_LOWERCASE=True
SECURITY_PASSWORD_REQUIRE_DIGIT=True
SECURITY_PASSWORD_REQUIRE_SPECIAL=True

# Vector Search Settings
# Path to store FAISS index files
VECTOR_VECTOR_INDEX_PATH=data/faiss_index
# Dimension of vector embeddings
VECTOR_VECTOR_DIMENSION=768
# FAISS index type (IVFFlat, IndexFlatIP, etc.)
VECTOR_INDEX_TYPE=IVFFlat
# Default number of top results to return
VECTOR_DEFAULT_TOP_K=5
# Similarity threshold for relevant documents
VECTOR_SIMILARITY_THRESHOLD=0.7
# Number of clusters for IVF indices
VECTOR_NLIST=100
# Number of clusters to explore during search
VECTOR_NPROBE=10

# LLM Settings
# OpenAI API key (CHANGE THIS IN PRODUCTION!)
LLM_OPENAI_API_KEY=your-openai-api-key
# LLM model to use
LLM_LLM_MODEL=gpt-3.5-turbo
# Temperature for response generation (0-1)
LLM_TEMPERATURE=0.7
# Maximum tokens in generated response
LLM_MAX_TOKENS=500
# Maximum context window size
LLM_CONTEXT_WINDOW_SIZE=4000
# Request timeout in seconds
LLM_REQUEST_TIMEOUT=30
# Maximum number of retries for LLM requests
LLM_MAX_RETRIES=3
# Whether to cache LLM responses (True/False)
LLM_USE_CACHE=True
# Cache TTL in seconds
LLM_CACHE_TTL_SECONDS=3600

# Document Settings
# Path to store uploaded documents
DOCUMENT_DOCUMENT_STORAGE_PATH=data/documents
# Maximum document size in MB
DOCUMENT_MAX_DOCUMENT_SIZE_MB=10
# Allowed document MIME types (comma-separated)
DOCUMENT_ALLOWED_DOCUMENT_TYPES=application/pdf
# Document chunk size in characters
DOCUMENT_CHUNK_SIZE=1000
# Overlap between chunks in characters
DOCUMENT_CHUNK_OVERLAP=200

# Feedback Settings
# Enable feedback collection (True/False)
FEEDBACK_ENABLE_FEEDBACK=True
# Enable reinforcement learning (True/False)
FEEDBACK_ENABLE_REINFORCEMENT_LEARNING=True
# Batch size for feedback processing
FEEDBACK_FEEDBACK_BATCH_SIZE=100
# Frequency of RL updates in hours
FEEDBACK_RL_UPDATE_FREQUENCY_HOURS=24
# Learning rate for reinforcement learning
FEEDBACK_LEARNING_RATE=0.001